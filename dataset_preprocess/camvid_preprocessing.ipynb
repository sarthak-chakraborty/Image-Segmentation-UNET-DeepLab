{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from PIL import Image\n",
    "from pylab import *\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_to_tensor(fname, output_height=256, output_width=256, normalize_data=False):\n",
    "    '''Function to read images from given image file path, and provide resized images as tensors\n",
    "        Inputs: \n",
    "            fname - image file path\n",
    "            output_height - required output image height\n",
    "            output_width - required output image width\n",
    "            normalize_data - if True, normalize data to be centered around 0 (mean 0, range 0 to 1)\n",
    "        Output: Processed image tensors\n",
    "    '''\n",
    "    \n",
    "    # Read the image as a tensor\n",
    "    img_strings = tf.io.read_file(fname)\n",
    "    imgs_decoded = tf.image.decode_jpeg(img_strings)\n",
    "    \n",
    "    # Resize the image\n",
    "    output = tf.image.resize(imgs_decoded, [output_height, output_width])\n",
    "    \n",
    "    # Normalize if required\n",
    "    if normalize_data:\n",
    "        output = (output - 128) / 128\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = './CamVid/'\n",
    "\n",
    "# Required image dimensions\n",
    "output_height = 256\n",
    "output_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(img_dir):\n",
    "    '''Function to get all image directories, read images and masks in separate tensors\n",
    "        Inputs: \n",
    "            img_dir - file directory\n",
    "        Outputs \n",
    "            frame_tensors, masks_tensors, frame files list, mask files list\n",
    "    '''\n",
    "    \n",
    "    # Get the file names list from provided directory\n",
    "    file_list = [f for f in os.listdir(img_dir) if os.path.isfile(os.path.join(img_dir, f))]\n",
    "    \n",
    "    # Separate frame and mask files lists, exclude unnecessary files\n",
    "    frames_list = [file for file in file_list if ('_L' not in file) and ('txt' not in file) and ('zip' not in file) and ('ipynb' not in file)]\n",
    "    masks_list = [file for file in file_list if ('_L' in file) and ('txt' not in file) and ('zip' not in file) and ('ipynb' not in file)]\n",
    "    \n",
    "    print('{} frame files found in the provided directory.'.format(len(frames_list)))\n",
    "    print('{} mask files found in the provided directory.'.format(len(masks_list)))\n",
    "    \n",
    "    # Create file paths from file names\n",
    "    frames_paths = [os.path.join(img_dir, fname) for fname in frames_list]\n",
    "    masks_paths = [os.path.join(img_dir, fname) for fname in masks_list]\n",
    "    \n",
    "    # Create dataset of tensors\n",
    "    frame_data = tf.data.Dataset.from_tensor_slices(frames_paths)\n",
    "    masks_data = tf.data.Dataset.from_tensor_slices(masks_paths)\n",
    "    \n",
    "    # Read images into the tensor dataset\n",
    "    frame_tensors = frame_data.map(_read_to_tensor)\n",
    "    masks_tensors = masks_data.map(_read_to_tensor)\n",
    "    \n",
    "    print('Completed importing {} frame images from the provided directory.'.format(len(frames_list)))\n",
    "    print('Completed importing {} mask images from the provided directory.'.format(len(masks_list)))\n",
    "    \n",
    "    return frame_tensors, masks_tensors, frames_list, masks_list\n",
    "\n",
    "frame_tensors, masks_tensors, frames_list, masks_list = read_images(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make an iterator to extract images from the tensor dataset\n",
    "frame_batches = tf.compat.v1.data.make_one_shot_iterator(frame_tensors)  # outside of TF Eager, we would use make_one_shot_iterator\n",
    "mask_batches = tf.compat.v1.data.make_one_shot_iterator(masks_tensors)\n",
    "\n",
    "n_images_to_show = 5\n",
    "\n",
    "for i in range(n_images_to_show):\n",
    "    \n",
    "    # Get the next image from iterator\n",
    "    frame = frame_batches.next().numpy().astype(np.uint8)\n",
    "    mask = mask_batches.next().numpy().astype(np.uint8)\n",
    "    \n",
    "    #Plot the corresponding frames and masks\n",
    "    fig = plt.figure()\n",
    "    fig.add_subplot(1,2,1)\n",
    "    plt.imshow(frame)\n",
    "    fig.add_subplot(1,2,2)\n",
    "    plt.imshow(mask)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './data/'\n",
    "\n",
    "# Create folders to hold images and masks\n",
    "folders = ['train_frames/train', 'train_masks/train', 'val_frames/val', 'val_masks/val']\n",
    "\n",
    "\n",
    "for folder in folders:\n",
    "    try:\n",
    "        os.makedirs(DATA_PATH + folder)\n",
    "    except Exception as e: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_image_folder_structure(frames, masks, frames_list, masks_list):\n",
    "    '''Function to save images in the appropriate folder directories \n",
    "        Inputs: \n",
    "            frames - frame tensor dataset\n",
    "            masks - mask tensor dataset\n",
    "            frames_list - frame file paths\n",
    "            masks_list - mask file paths\n",
    "    '''\n",
    "    #Create iterators for frames and masks\n",
    "    frame_batches = tf.compat.v1.data.make_one_shot_iterator(frames)  # outside of TF Eager, we would use make_one_shot_iterator\n",
    "    mask_batches = tf.compat.v1.data.make_one_shot_iterator(masks)\n",
    "    \n",
    "    frames, masks = [], []\n",
    "    \n",
    "    #Iterate over the train images while saving the frames and masks in appropriate folders\n",
    "    dir_name='train'\n",
    "    for file in zip(frames_list[:-round(0.2*len(frames_list))],masks_list[:-round(0.2*len(masks_list))]):\n",
    "        \n",
    "        \n",
    "        #Convert tensors to numpy arrays\n",
    "        frame = frame_batches.next().numpy().astype(np.uint8)\n",
    "        mask = mask_batches.next().numpy().astype(np.uint8)\n",
    "        \n",
    "        frames.append(frame)\n",
    "        masks.append(mask)\n",
    "        \n",
    "        #Convert numpy arrays to images\n",
    "        frame = Image.fromarray(frame)\n",
    "        mask = Image.fromarray(mask)\n",
    "        \n",
    "        #Save frames and masks to correct directories\n",
    "        frame.save(DATA_PATH+'{}_frames/{}'.format(dir_name,dir_name)+'/'+file[0])\n",
    "        mask.save(DATA_PATH+'{}_masks/{}'.format(dir_name,dir_name)+'/'+file[1])\n",
    "    \n",
    "    #Iterate over the val images while saving the frames and masks in appropriate folders\n",
    "    dir_name='val'\n",
    "    for file in zip(frames_list[-round(0.2*len(frames_list)):],masks_list[-round(0.2*len(masks_list)):]):\n",
    "        \n",
    "        \n",
    "        #Convert tensors to numpy arrays\n",
    "        frame = frame_batches.next().numpy().astype(np.uint8)\n",
    "        mask = mask_batches.next().numpy().astype(np.uint8)\n",
    "        \n",
    "        #Convert numpy arrays to images\n",
    "        frame = Image.fromarray(frame)\n",
    "        mask = Image.fromarray(mask)\n",
    "        \n",
    "        #Save frames and masks to correct directories\n",
    "        frame.save(DATA_PATH+'{}_frames/{}'.format(dir_name,dir_name)+'/'+file[0])\n",
    "        mask.save(DATA_PATH+'{}_masks/{}'.format(dir_name,dir_name)+'/'+file[1])\n",
    "    \n",
    "    print(\"Saved {} frames to directory {}\".format(len(frames_list),DATA_PATH))\n",
    "    print(\"Saved {} masks to directory {}\".format(len(masks_list),DATA_PATH))\n",
    "    \n",
    "    return np.array(frames), np.array(masks)\n",
    "    \n",
    "frames, masks = generate_image_folder_structure(frame_tensors, masks_tensors, frames_list, masks_list)\n",
    "\n",
    "#generate_image_folder_structure(train_frames, train_masks, val_files, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'label_colors.txt'\n",
    "\n",
    "from shutil import copyfile\n",
    "copyfile(img_dir+file_name, DATA_PATH+file_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
