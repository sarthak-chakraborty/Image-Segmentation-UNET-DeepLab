{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *\n",
    "import os\n",
    "import sys\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import *\n",
    "\n",
    "\n",
    "#from tensorflow.keras.engine import Layer\n",
    "from tensorflow.keras.applications.vgg16 import *\n",
    "from tensorflow.keras.models import *\n",
    "#from tensorflow.keras.applications.imagenet_utils import _obtain_input_shape\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D, Cropping2D, Conv2D\n",
    "from tensorflow.keras.layers import Input, Add, Dropout, Permute, add\n",
    "from tensorflow.compat.v1.layers import conv2d_transpose\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.python.client import device_lib \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform([3, 3])\n",
    "\n",
    "print(\"Is there a GPU available: \"),\n",
    "print(tf.config.list_physical_devices())\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('XLA_GPU')))\n",
    "\n",
    "print(\"Is the Tensor on GPU #0:  \"),\n",
    "print(x.device.endswith('GPU:0'))\n",
    "\n",
    "print(\"Device name: {}\".format((x.device)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.executing_eagerly())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_dir = 'dataset_preprocess/data/'\n",
    "\n",
    "# Required image dimensions\n",
    "output_height = 256\n",
    "output_width = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'dataset_preprocess/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Target Class definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_code(l):\n",
    "    '''Function to parse lines in a text file, returns separated elements (label codes and names in this case)\n",
    "    '''\n",
    "    if len(l.strip().split(\"\\t\")) == 2:\n",
    "        a, b = l.strip().split(\"\\t\")\n",
    "        return tuple(int(i) for i in a.split(' ')), b\n",
    "    else:\n",
    "        a, b, c = l.strip().split(\"\\t\")\n",
    "        return tuple(int(i) for i in a.split(' ')), c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_codes, label_names = zip(*[parse_code(l) for l in open(img_dir+\"label_colors.txt\")])\n",
    "label_codes, label_names = list(label_codes), list(label_names)\n",
    "label_codes[:5], label_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_codes, label_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create useful label and code conversion dictionaries\n",
    "_These will be used for:_\n",
    "- One hot encoding the mask labels for model training\n",
    "- Decoding the predicted labels for interpretation and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "code2id = {v:k for k,v in enumerate(label_codes)}\n",
    "id2code = {k:v for k,v in enumerate(label_codes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name2id = {v:k for k,v in enumerate(label_names)}\n",
    "id2name = {k:v for k,v in enumerate(label_names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "id2name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for one hot encoding rgb labels, and decoding encoded predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rgb_to_onehot(rgb_image, colormap = id2code):\n",
    "    '''Function to one hot encode RGB mask labels\n",
    "        Inputs: \n",
    "            rgb_image - image matrix (eg. 256 x 256 x 3 dimension numpy ndarray)\n",
    "            colormap - dictionary of color to label id\n",
    "        Output: One hot encoded image of dimensions (height x width x num_classes) where num_classes = len(colormap)\n",
    "    '''\n",
    "    num_classes = len(colormap)\n",
    "    shape = rgb_image.shape[:2]+(num_classes,)\n",
    "    encoded_image = np.zeros( shape, dtype=np.int8 )\n",
    "    for i, cls in enumerate(colormap):\n",
    "        encoded_image[:,:,i] = np.all(rgb_image.reshape( (-1,3) ) == colormap[i], axis=1).reshape(shape[:2])\n",
    "    return encoded_image\n",
    "\n",
    "\n",
    "def onehot_to_rgb(onehot, colormap = id2code):\n",
    "    '''Function to decode encoded mask labels\n",
    "        Inputs: \n",
    "            onehot - one hot encoded image matrix (height x width x num_classes)\n",
    "            colormap - dictionary of color to label id\n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    single_layer = np.argmax(onehot, axis=-1)\n",
    "    output = np.zeros( onehot.shape[:2]+(3,) )\n",
    "    for k in colormap.keys():\n",
    "        output[single_layer==k] = colormap[k]\n",
    "    return np.uint8(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalizing only frame images, since masks contain label info\n",
    "data_gen_args = dict(rescale=1./255)\n",
    "\n",
    "mask_gen_args = dict()\n",
    "\n",
    "\n",
    "train_frames_datagen = ImageDataGenerator(**data_gen_args)\n",
    "train_masks_datagen = ImageDataGenerator(**mask_gen_args)\n",
    "val_frames_datagen = ImageDataGenerator(**data_gen_args)\n",
    "val_masks_datagen = ImageDataGenerator(**mask_gen_args)\n",
    "test_frames_datagen = ImageDataGenerator(**data_gen_args)\n",
    "test_masks_datagen = ImageDataGenerator(**mask_gen_args)\n",
    "\n",
    "# Seed defined for aligning images and their masks\n",
    "seed = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TrainAugmentGenerator(seed=1, batch_size=32):\n",
    "    '''Train Image data generator\n",
    "        Inputs: \n",
    "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
    "            batch_size - number of images to import at a time\n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    train_image_generator = train_frames_datagen.flow_from_directory(\n",
    "    DATA_PATH + 'train_frames/',\n",
    "    batch_size = batch_size, seed = seed)\n",
    "\n",
    "    train_mask_generator = train_masks_datagen.flow_from_directory(\n",
    "    DATA_PATH + 'train_masks/',\n",
    "    batch_size = batch_size, seed = seed)\n",
    "\n",
    "    while True:\n",
    "        X1i = train_image_generator.next()\n",
    "        X2i = train_mask_generator.next()\n",
    "        \n",
    "        #One hot encoding RGB images\n",
    "        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n",
    "        \n",
    "        yield X1i[0], np.asarray(mask_encoded)\n",
    "\n",
    "def ValAugmentGenerator(seed=1, batch_size=32):\n",
    "    '''Validation Image data generator\n",
    "        Inputs: \n",
    "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
    "            batch_size - number of images to import at a time\n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    val_image_generator = val_frames_datagen.flow_from_directory(\n",
    "    DATA_PATH + 'val_frames/',\n",
    "    batch_size = batch_size, seed = seed)\n",
    "\n",
    "\n",
    "    val_mask_generator = val_masks_datagen.flow_from_directory(\n",
    "    DATA_PATH + 'val_masks/',\n",
    "    batch_size = batch_size, seed = seed)\n",
    "\n",
    "\n",
    "    while True:\n",
    "        X1i = val_image_generator.next()\n",
    "        X2i = val_mask_generator.next()\n",
    "        \n",
    "        #One hot encoding RGB images\n",
    "        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n",
    "        \n",
    "        yield X1i[0], np.asarray(mask_encoded)\n",
    "        \n",
    "\n",
    "def TestAugmentGenerator(seed=1, batch_size=5):\n",
    "    '''Validation Image data generator\n",
    "        Inputs: \n",
    "            seed - seed provided to the flow_from_directory function to ensure aligned data flow\n",
    "            batch_size - number of images to import at a time\n",
    "        Output: Decoded RGB image (height x width x 3) \n",
    "    '''\n",
    "    test_image_generator = test_frames_datagen.flow_from_directory(\n",
    "    DATA_PATH + 'test_frames/',\n",
    "    batch_size = batch_size, seed = seed)\n",
    "\n",
    "\n",
    "    test_mask_generator = test_masks_datagen.flow_from_directory(\n",
    "    DATA_PATH + 'test_masks/',\n",
    "    batch_size = batch_size, seed = seed)\n",
    "\n",
    "\n",
    "    while True:\n",
    "        X1i = test_image_generator.next()\n",
    "        X2i = test_mask_generator.next()\n",
    "        \n",
    "        #One hot encoding RGB images\n",
    "        mask_encoded = [rgb_to_onehot(X2i[0][x,:,:,:], id2code) for x in range(X2i[0].shape[0])]\n",
    "        \n",
    "        yield X1i[0], np.asarray(mask_encoded)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Unet(n_filters=16, dilation_rate=1, n_classes=32):\n",
    "    '''Validation Image data generator\n",
    "        Inputs: \n",
    "            n_filters - base convolution filters\n",
    "            bn - flag to set batch normalization\n",
    "            dilation_rate - convolution dilation rate\n",
    "        Output: Unet keras Model\n",
    "    '''\n",
    "    #Define input batch shape\n",
    "    inputs = Input(shape=(256, 256, 3))\n",
    "    \n",
    "    conv1 = Conv2D(n_filters * 1, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(inputs)\n",
    "    conv1 = Conv2D(n_filters * 1, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv1)\n",
    "\n",
    "    conv2 = Conv2D(n_filters * 2, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(pool1)  \n",
    "    conv2 = Conv2D(n_filters * 2, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv2)\n",
    "\n",
    "    conv3 = Conv2D(n_filters * 4, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(pool2)  \n",
    "    conv3 = Conv2D(n_filters * 4, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv3)   \n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv3)\n",
    "\n",
    "    conv4 = Conv2D(n_filters * 8, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(pool3)   \n",
    "    conv4 = Conv2D(n_filters * 8, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv4)   \n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2), data_format='channels_last')(conv4)\n",
    "\n",
    "    conv5 = Conv2D(n_filters * 16, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(pool4)   \n",
    "    conv5 = Conv2D(n_filters * 16, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv5)  \n",
    "    up6 = concatenate([UpSampling2D(size=(2, 2))(conv5), conv4], axis=3)\n",
    "    \n",
    "    conv6 = Conv2D(n_filters * 8, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(up6)    \n",
    "    conv6 = Conv2D(n_filters * 8, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv6)   \n",
    "    up7 = concatenate([UpSampling2D(size=(2, 2))(conv6), conv3], axis=3)\n",
    "    \n",
    "    conv7 = Conv2D(n_filters * 4, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(up7) \n",
    "    conv7 = Conv2D(n_filters * 4, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv7)   \n",
    "    up8 = concatenate([UpSampling2D(size=(2, 2))(conv7), conv2], axis=3)\n",
    "    \n",
    "    conv8 = Conv2D(n_filters * 2, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(up8)  \n",
    "    conv8 = Conv2D(n_filters * 2, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv8)  \n",
    "    up9 = concatenate([UpSampling2D(size=(2, 2))(conv8), conv1], axis=3)\n",
    "    \n",
    "    conv9 = Conv2D(n_filters * 1, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(up9)  \n",
    "    conv9 = Conv2D(n_filters * 1, (3, 3), activation='relu', padding = 'same', dilation_rate = dilation_rate)(conv9)  \n",
    "    conv10 = Conv2D(n_classes, (1, 1), activation='softmax', padding = 'same', dilation_rate = dilation_rate)(conv9)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=conv10)\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = Unet(n_filters=32, n_classes=len(id2code))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tb = TensorBoard(log_dir='logs', write_graph=True)\n",
    "mc = ModelCheckpoint(mode='max', filepath='weights_checkpoint-{epoch:003d}.h5', monitor='accuracy', save_best_only='False', save_weights_only='True', verbose=1)\n",
    "es = EarlyStopping(mode='max', monitor='val_accuracy', patience=10, verbose=1)\n",
    "callbacks = [tb, mc, es]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Pascal VOC (Change accordingly)\n",
    "n_train_samples = 2976\n",
    "n_val_samples = 500\n",
    "\n",
    "batch_size = 32\n",
    "steps_per_epoch = np.ceil(n_train_samples / float(batch_size))\n",
    "steps_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_steps = np.ceil(n_val_samples / float(batch_size))\n",
    "validation_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "result = model.fit_generator(TrainAugmentGenerator(batch_size=batch_size), steps_per_epoch=steps_per_epoch ,\n",
    "                validation_data = ValAugmentGenerator(batch_size=batch_size), \n",
    "                validation_steps = validation_steps, epochs=num_epochs, callbacks=callbacks)\n",
    "model.save_weights(\"camvid_150_epochs.h5\", overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation historical plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual number of epochs model was trained for\n",
    "N = len(result.history['loss'])\n",
    "\n",
    "#Plot the model evaluation history\n",
    "plt.style.use(\"ggplot\")\n",
    "fig = plt.figure(figsize=(20,8))\n",
    "\n",
    "fig.add_subplot(1,2,1)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.plot(np.arange(0, N), result.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), result.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "fig.add_subplot(1,2,2)\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.plot(np.arange(0, N), result.history[\"accuracy\"], label=\"train_accuracy\")\n",
    "plt.plot(np.arange(0, N), result.history[\"val_accuracy\"], label=\"val_accuracy\")\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing_gen = ValAugmentGenerator()\n",
    "# testing_gen = TestAugmentGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_img, batch_mask = next(testing_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(img, y_true, y_pred):  \n",
    "    fig = plt.figure(figsize=(20,8))\n",
    "\n",
    "    ax1 = fig.add_subplot(1,4,1)\n",
    "    ax1.imshow(img)\n",
    "    ax1.title.set_text('Actual frame')\n",
    "    ax1.grid(b=None)\n",
    "\n",
    "    ax2 = fig.add_subplot(1,4,2)\n",
    "    ax2.set_title('Ground truth labels')\n",
    "    ax2.imshow(onehot_to_rgb(y_true,id2code))\n",
    "    ax2.grid(b=None)\n",
    "\n",
    "    ax3 = fig.add_subplot(1,4,3)\n",
    "    ax3.set_title('Predicted labels')\n",
    "    ax3.imshow(onehot_to_rgb(y_pred[0], id2code))\n",
    "    ax3.grid(b=None)\n",
    "    \n",
    "    ax3 = fig.add_subplot(1,4,4)\n",
    "    ax3.set_title('Difference')\n",
    "    ax3.imshow(onehot_to_rgb(y_pred[0], id2code) - onehot_to_rgb(y_true,id2code))\n",
    "    ax3.grid(b=None)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mIOU(gt, preds):\n",
    "    ulabels = np.unique(gt)\n",
    "    iou = np.zeros(len(ulabels))\n",
    "    for k, u in enumerate(ulabels):\n",
    "        inter = (gt == u) & (preds==u)\n",
    "        union = (gt == u) | (preds==u)\n",
    "        iou[k] = inter.sum()/union.sum()\n",
    "    return np.round(iou.mean(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(batch_img)):\n",
    "    img = batch_img[i]\n",
    "    x = np.expand_dims(img, axis=0)\n",
    "    y_true = batch_mask[i]\n",
    "\n",
    "    model.load_weights('weights_checkpoint-050.h5')\n",
    "    y_pred = model.predict(x)\n",
    "    plotImages(img, y_true, y_pred)\n",
    "    y = np.argmax(y_true, axis=-1)\n",
    "    gt = y.astype('int32')\n",
    "    pred1 = np.argmax(y_pred, axis=-1)\n",
    "\n",
    "    print('mIOU: {}'.format(mIOU(gt, pred1)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
